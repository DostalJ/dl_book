{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backpropagation_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "bXDt1QFarxhc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook under construction \n",
        "\n",
        "## Backpropagation with Tensorflow\n",
        "\n",
        "* Builds the computational Graph for the forward pass\n",
        "* Displays the graph on TensorBoard\n",
        "* Using the TensorFlow Optimizer to minimize the loss\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/backpropagation_tf.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"open in colab\">\n",
        "</a>\n",
        "| [open in colab](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/backpropagation_tf.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ZkDvlnMjJxRe",
        "colab_type": "code",
        "outputId": "896a6720-35ed-4364-da43-482d7d975869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function\n",
        "print('TF Version:', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version: 1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zACb9J35KP92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
        "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
        "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
        "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
        "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
        "x = np.asarray(x, np.float32) \n",
        "y = np.asarray(y, np.float32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PVZDLZA0J3M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Doing the back propagation by hand for the example"
      ]
    },
    {
      "metadata": {
        "id": "uigQYLMs0B6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = [1]\n",
        "x = [2]\n",
        "x = np.asarray(x, np.float32) \n",
        "y = np.asarray(y, np.float32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8thmhCF0fq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x,y are one dimensional numpy arrays\n",
        "# Defining the graph (construction phase)\n",
        "tf.reset_default_graph()   #  “Wipe the blackboard”, construct a new graph\n",
        "a_  = tf.Variable(3.0, name='a_var') #  Variables, with starting values, can be optimize later\n",
        "b_  = tf.Variable(4.0, name='b_var')  #  we name them so that they look nicer in the graph\n",
        "x_  = tf.constant(x, name='x_const')  # Constants these are fixed tensors holding the data values \n",
        "y_  = tf.constant(y, name='y_const')  \n",
        "\n",
        "\n",
        "# We know do it step by step so that we can calculate the intermediate values and gradients\n",
        "ax_ = a_* x_\n",
        "y_hat_ = ax_ + b_\n",
        "r_ = y_hat_ - y_\n",
        "s_ = tf.square(r_)\n",
        "mse_ = tf.reduce_mean(s_) #The final result, the MSE. Still symbolical\n",
        "\n",
        "grads_ = tf.gradients(mse_, [a_,b_,ax_,y_hat_,r_,s_])\n",
        "\n",
        "grads_s_ = tf.gradients(s_,r_ )\n",
        "grads_s_ = tf.gradients(s_,r_ )\n",
        "\n",
        "writer = tf.summary.FileWriter(\"linreg/\", tf.get_default_graph())\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-vlPfRlvfOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TOOD show on tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5WPxq0WSxkx6",
        "colab_type": "code",
        "outputId": "89989161-9181-4d94-8076-10a49328c2b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session() #Starts a session and grabs memory and other resources\n",
        "vals = sess.run([mse_, a_,b_,ax_,y_hat_,r_,s_], {a_:3,b_:4}) # Letting the variables a=3 b=1 flow through the graph\n",
        "for p in vals:\n",
        "  print(p)\n",
        "\n",
        "\n",
        "print(\"Hallo\")\n",
        "grads = sess.run(grads_, {a_:3,b_:4}) # Letting the variables a=3 b=1 flow through the graph\n",
        "for p in grads:\n",
        "  print(p)\n",
        "\n",
        "\n",
        "sess.close() # Don't forget to close the session"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81.0\n",
            "3.0\n",
            "4.0\n",
            "[6.]\n",
            "[10.]\n",
            "[9.]\n",
            "[81.]\n",
            "Hallo\n",
            "36.0\n",
            "18.0\n",
            "[18.]\n",
            "[18.]\n",
            "[18.]\n",
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JoSIz0E73JnD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We add an addtional operation to the graph optimizing the mse_\n",
        "train_op_ = tf.train.GradientDescentOptimizer(learning_rate=0.00001).minimize(mse_) \n",
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer()) #Doing the initialization on the concrete realization of the graph\n",
        "    for i in range(1):\n",
        "      _, mse, grads,grads_rs, a, b = sess.run([train_op_, mse_, grads_,grads_s_, a_, b_])#fetch all the gradients here \n",
        "#      # These line are just for printing ou the gradients\n",
        "#      for g, v in grads_and_vars:\n",
        "#        tf.summary.histogram(v.name, v)\n",
        "#        tf.summary.histogram(v.name + '_grad', g)\n",
        "#      merged = tf.summary.merge_all()\n",
        "#      writer = tf.summary.FileWriter('train_log_layer', tf.get_default_graph())\n",
        "#      if (i % 10000 == 0): #Trick not to print so often\n",
        "#        print(a, b, mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "reQ0PK5rvNRN",
        "colab_type": "code",
        "outputId": "65729a3a-8ecb-4f15-dbac-68de4a1cfda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(a,b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.99964 3.99982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hPdw0dyXvGD2",
        "colab_type": "code",
        "outputId": "e13ba91c-8beb-4a51-ac8a-90c5103c3fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(grads)\n",
        "print(grads_rs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36.0, 18.0, array([18.], dtype=float32), array([18.], dtype=float32), array([18.], dtype=float32), array([1.], dtype=float32)]\n",
            "[array([18.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6hFXF7lmvWuV",
        "colab_type": "code",
        "outputId": "c1c0ea92-4237-43dc-a784-be62e5a0f48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#grads_ = tf.gradients(mse_, [a_,b_,ax_,y_hat_,r_,rs_])\n",
        "grads[5]*grads_rs*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "LxMcy1iYqwYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's add an optimizer to the loss \n",
        "loss = rss #This is usually called loss and we want to minimize the loss.\n",
        "train_op = tf.train.AdamOptimizer().minimize(loss) \n",
        "init_op = tf.global_variables_initializer()\n",
        "with tf.Session() as sess: \n",
        "    sess.run(init_op) #Doing the initialization on the concrete realization of the graph\n",
        "    for i in range(100000):\n",
        "      _,a_val, b_val, loss_val = sess.run([train_op,a,b, loss])\n",
        "      if (i % 10000 == 0): #Trick not to print so often\n",
        "        print(a_val, b_val, loss_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYNRo3eFvSQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = rss #This is usually called loss and we want to minimize the loss.\n",
        "train_op = tf.train.RMSPropOptimizer(learning_rate=0.01).minimize(loss)\n",
        "init_op = tf.global_variables_initializer()\n",
        "with tf.Session() as sess: \n",
        "    sess.run(init_op) #Doing the initialization on the concrete realization of the graph\n",
        "    for i in range(100000):\n",
        "      _,a_val, b_val, loss_val = sess.run([train_op,a,b, loss])\n",
        "      if (i % 10000 == 0): #Trick not to print so often\n",
        "        print(a_val, b_val, loss_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDJFqyRDG-5Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "av = np.linspace(-3,3,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBiVJXhgH_1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resv = np.zeros_like(av)\n",
        "for i,a in enumerate(av):\n",
        "  resv[i] = np.sum((a*x + b - y)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fItPOsXmIgDx",
        "colab_type": "code",
        "outputId": "6343875a-1402-4a86-a56c-b7549079380a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(av, resv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fed72478e90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fed75e70d10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "93MFxmaGumoy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}