---
layout: default
mathjax: true
title: dl book
---
# dl book notebooks overview

You can use the notebooks below by clicking on the Colab Notebooks link or running them locally on your machine. 

To run them locally, you can either 

* install the required software (Python with TensorFlow) or 
* use the provided Docker container as described here [Link will follow upon finishing the book].  

## Chapter 2: Neural network architectures

| Number  |      Topic    |      Github    |      Colab    |
|:--------:|:--------------|:---------------|:--------------|
| 1        | Banknote classification with fcNN |[nb_ch02_01](https://github.com/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_01.ipynb) |[nb_ch02_01](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_01.ipynb)|
| 2        |MNIST digit classification with shuffling|[nb_ch02_02](https://github.com/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_02.ipynb) |[nb_ch02_02](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_02.ipynb)|
| 3        |MNIST digit classification with fcNN|[nb_ch02_02a](https://github.com/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_02a.ipynb) |[nb_ch02_02a](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_02a.ipynb)|
| 4        |CNN edge lover|[nb_ch02_03](https://github.com/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_03.ipynb) |[nb_ch02_03](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_03.ipynb)|
| 5        |Causal and time dilated convolutions|[nb_ch02_04](https://github.com/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_04.ipynb) |[nb_ch02_04](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_02/nb_ch02_04.ipynb)|

## Chapter 3: Principles of curve fitting

| Number  |      Topic    |      Github    |      Colab    |
|:--------:|:--------------|:---------------|:--------------|
| 1        |Gradient descent method for linear regression with one tunable parameter |[nb_ch03_01](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_01.ipynb) |[nb_ch03_01](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_01.ipynb)|
| 2        |Gradient descent method for linear regression |[nb_ch03_02](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_02.ipynb) |[nb_ch03_02](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_02.ipynb)|
| 3        |Linear regression with TensorFlow |[nb_ch03_03](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_03.ipynb) |[nb_ch03_03](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_03.ipynb)|
| 4        |Backpropagation by hand |[nb_ch03_04](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_04.ipynb) |[nb_ch03_04](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_04.ipynb)|
| 5        |Linear regression with Keras |[nb_ch03_05](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_05.ipynb) |[nb_ch03_05](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_05.ipynb)|
| 6        |Linear regression with TF Eager |[nb_ch03_06](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_06.ipynb) |[nb_ch03_06](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_06.ipynb)|
| 7        |Linear regression with Autograd |[nb_ch03_07](https://github.com/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_07.ipynb) |[nb_ch03_07](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_07.ipynb)|

## Chapter 4: Building loss functions with the likelihood approach

| Number  |      Topic    |      Github    |      Colab    |
|:--------:|:--------------|:---------------|:--------------|
| 1        |First example of the maximum likelihood principle: throwing a dice |[nb_ch04_01](https://github.com/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_01.ipynb) |[nb_ch04_01](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_01.ipynb)|
| 2        |Calculation of the loss function for classification |[nb_ch04_02](https://github.com/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_02.ipynb) |[nb_ch04_02](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_02.ipynb)|
| 3        |Calculation of the loss function for regression |[nb_ch04_03](https://github.com/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_03.ipynb) |[nb_ch04_03](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_03.ipynb)|
| 4        |Regression fit for non-linear relationships with non-constant variance |[nb_ch04_04](https://github.com/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_03.ipynb) |[nb_ch04_04](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_04/nb_ch04_04.ipynb)|
